{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a Linear Function\n",
    "\n",
    "In this notebook, we will look at 2 methods for creating Linear Functions:\n",
    " * Perceptron Learning Algorithm\n",
    " * Pocket Algorithm\n",
    " \n",
    " Each of these algorithms will generate a function $f(\\vec{x}) = \\vec{w}\\vec{x} = y$.  We will see how this function is generated in each case below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm (PLA)\n",
    "If we are trying to learn how to classify some data into to classes, and the data is linearly seperable, then we can use the PLA to find a classifier for this problem.  \n",
    "\n",
    "To use PLA, the y values must be either -1 or 1.  This is easy to achieve with any binary decision simply by assigning 1 to one decision and -1 to the other.\n",
    "\n",
    "The PLA looks like this:\n",
    "\n",
    "`\n",
    "Initialize `$\\vec{w}$` as uniform random\n",
    "While there are errors (that is, while ` $E_{in} \\ne 0$ `),\n",
    "  pick one `$x$` such that `$y \\neq sign(\\vec{w}\\vec{x})$`.\n",
    "  let `$\\vec{w} \\rightarrow \\vec{w} + y\\vec{x}$`.\n",
    "end`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pocket Algorithm\n",
    "The Pocket Algorithm is just the PLA with an added step where we keep the 'best' answer so far. This is used when the two classes are intermingled by the y-values not being linearly separable.\n",
    "\n",
    "`Initialize `$\\vec{w_0}$ ` randomly, ` $E_{in}(0) = 9e7$`.\n",
    "for `$t = 0, \\ldots, T-1$`,\n",
    "  Run PLA for one update to obtain `$\\vec{w_{t+1}}$`.\n",
    "  Calculate `$E_{in}(\\vec{w_{t+1}})$`.\n",
    "  If `$E_{in}(\\vec{w_{t+1}})$` is less than `$E_{in}(\\vec{w})$`, \n",
    "    Set `$\\vec{w} = \\vec{w_{t+1}}$`.\n",
    "  End\n",
    "End\n",
    "Return `$\\vec{w}$`.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $E_{in}$\n",
    "Each of these requires us to calculate $E_{in}$ which is a scalar sum of absolute value of errors for a single training step.  In math-speak, let the training step produce a function $h_t(x)$ at step $t$.  Then \n",
    "\n",
    "$$E_{in} = \\sum^N_{k=1}(|h_t(x_k) - y_k|)$$\n",
    "\n",
    "where $x_k$ and $y_k$ are rows and targets respectively, of the training data.  \n",
    "\n",
    "The linear algorithms above require this calculation as part of the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
